{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "18127266.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tqnhu2407/NLP/blob/master/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8CdSFVM4dXP",
        "colab_type": "text"
      },
      "source": [
        "# Đồ án 4: Phân lớp văn bản với kĩ thuật bình phương tối tiểu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCQ2kPkH5EAB",
        "colab_type": "text"
      },
      "source": [
        "## Thông tin cá nhân:\n",
        "\n",
        "Họ tên: Trần Quỳnh Như\n",
        "\n",
        "MSSV: 18127266"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gCo6ZGe4oqr",
        "colab_type": "text"
      },
      "source": [
        "## Các phần đã hoàn thành: 1 phần\n",
        "\n",
        "- Đọc dữ liệu và tiền xử lý dữ liệu (5 điểm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cy4NAir5NbL",
        "colab_type": "text"
      },
      "source": [
        "Import các thư viện cần thiết\n",
        "\n",
        "(3 cells dưới đây được cung cấp sẵn và không chỉnh sửa gì thêm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTiQmIT9ZwsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DON'T CHANGE this part: import libraries\n",
        "import numpy as np\n",
        "import scipy\n",
        "import json\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEJnDPwBZwsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DON'T CHANGE this part: read data path\n",
        "train_set_path, valid_set_path, random_number = input().split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj5L38gpZwsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO:\n",
        "# 1. preprocess: converting text to lowercase, coverting number, tokenization, removing stopword, stemming\n",
        "# 2. embedding: hitogram matrix\n",
        "# 3. classifier using linear regression\n",
        "# 4. accuracy (for metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hoa36NkzCjp",
        "colab_type": "text"
      },
      "source": [
        "Đọc file train.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7fqdczimRNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"train.json\", \"r\") as fin:\n",
        "    data = json.load(fin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqvm4B1S52rq",
        "colab_type": "text"
      },
      "source": [
        "Lọc ra các overall và reviewText từ file train.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0hgDKCsoF5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_json(data):\n",
        "\n",
        "    overall = []\n",
        "    reviewText = []\n",
        "    # Filter out all the overall and reviewText\n",
        "    for d in data:\n",
        "        for (key, value) in d.items():\n",
        "            if key == 'overall':\n",
        "                overall.append(value)\n",
        "            if key == 'reviewText':\n",
        "                reviewText.append(value)\n",
        "    \n",
        "    return overall, reviewText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EZp7t2y7aLD",
        "colab_type": "text"
      },
      "source": [
        "Ta được list các overall và list các reviewText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEv4v5D6Z4kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overall, reviewText = process_json(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0eMuGCm7EiW",
        "colab_type": "text"
      },
      "source": [
        "Download các packages punkt và stopwords để khi tiền xử lí ta có thể tách từ và loại bỏ stop words được"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtXnwbGsD-hK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "1181c18d-945c-4762-ace0-7c25f94e6fab"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaAi3rD17fSc",
        "colab_type": "text"
      },
      "source": [
        "Hàm tiền xử lí dữ liệu:\n",
        "\n",
        "Xét mỗi review trong list reviewText:\n",
        "\n",
        "- Chuyển tất cả kí tự thành kí tự thường bằng cách gọi .lower()\n",
        "\n",
        "- Thay số bằng kí tự 'num' và xóa các dấu câu bằng hàm re.sub()\n",
        "\n",
        "- Tách từ bằng hàm word_tokenize()\n",
        "\n",
        "- Loại bỏ stop words bằng cách xét xem từ đó có nằm trong list stop_words hay không\n",
        "\n",
        "- Stemming bằng cách gán ps = ProterStemmer() và gọi ps.stem()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0M0Dwk8Zwsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(reviewText):\n",
        "\n",
        "    reviews = reviewText.copy()\n",
        "    stop_words = set(stopwords.words('english')) \n",
        "    new_reviews = []\n",
        "    \n",
        "    for i in range(len(reviews)):\n",
        "\n",
        "        # Lowercase all the letters\n",
        "        reviews[i] = reviews[i].lower()\n",
        "        # Replace all numbers with 'num\n",
        "        reviews[i] = re.sub('\\d+', 'num', reviews[i])\n",
        "        # Remove punctuation . , ?\n",
        "        reviews[i] = re.sub(r'[^\\w\\s]', '', reviews[i])\n",
        "        # Split words\n",
        "        word_tokens = word_tokenize(reviews[i])\n",
        "        # Remove stop words\n",
        "        removed_stopwords = [w for w in word_tokens if w not in stop_words]\n",
        "        # Stemming\n",
        "        ps = PorterStemmer()\n",
        "        stemmed_sentence = [ps.stem(w) for w in removed_stopwords]\n",
        "        new_reviews.append(stemmed_sentence)\n",
        "    \n",
        "    return new_reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orjfFjcD-cIw",
        "colab_type": "text"
      },
      "source": [
        "Tạo từ điển bằng cách: xét tất cả các từ trong tất cả các reviews, nếu từ đó chưa có trong bộ từ điển thì ta append vào.\n",
        "\n",
        "Cuối cùng ta append từ 'unk' để đại diện cho những từ chưa được học."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip-s_QVTvS0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vocabs(reviews):\n",
        "\n",
        "    vocabs = []\n",
        "\n",
        "    for review in reviews:\n",
        "        for r in review:\n",
        "            if r not in vocabs:\n",
        "                vocabs.append(r)\n",
        "    \n",
        "    vocabs.append('unk')\n",
        "\n",
        "    return vocabs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlo_nEsE-oag",
        "colab_type": "text"
      },
      "source": [
        "Tạo word count vector (embedding) bằng cách: \n",
        "\n",
        "Đếm số lần xuất hiện của các từ của 1 reviews nếu từ đó có trong từ điển. \n",
        "\n",
        "Nếu từ đó không có trong từ điển, ta đếm riêng chúng và gán vào cuối mỗi dòng trong list embedded (vì từ cuối của từ điển là 'unk' đại diện cho các từ chưa được học)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stBUyB24t3Mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedded(reviews, vocabs):\n",
        "\n",
        "    embedded = []\n",
        "\n",
        "    for r in reviews:\n",
        "\n",
        "        embedded.append([])\n",
        "        embedded[-1] = [r.count(v) for v in vocabs]\n",
        "\n",
        "        count_unk = 0\n",
        "        for w in r:\n",
        "            if w not in vocabs:\n",
        "                count_unk += 1\n",
        "        embedded[-1][-1] = count_unk # Count the number of unknown words\n",
        "    \n",
        "    return embedded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8ifDSdY_eRj",
        "colab_type": "text"
      },
      "source": [
        "Gọi các hàm trên"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-0T32-VqINv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_reviews = preprocess(reviewText)\n",
        "vocabs = create_vocabs(new_reviews)\n",
        "embedded = create_embedded(new_reviews, vocabs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEACTt05_g4l",
        "colab_type": "text"
      },
      "source": [
        "Đọc file valid.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvi8WSpB8Ibc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"valid.json\", \"r\") as fin:\n",
        "    data_valid = json.load(fin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM4pKKEK_mpC",
        "colab_type": "text"
      },
      "source": [
        "Lọc ra overall và reviewText từ file valid.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuXXHVd88RUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overall_valid, reviewText_valid = process_json(data_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCa6Xl-YAVNo",
        "colab_type": "text"
      },
      "source": [
        "Tiền xử lí và embedding các reviews từ file valid.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QjDmOQY8UHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_valid = preprocess(reviewText)\n",
        "embedded_valid = create_embedded(reviews_valid, vocabs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_FeoC6dGK17",
        "colab_type": "text"
      },
      "source": [
        "# Tham khảo\n",
        "\n",
        "https://docs.python.org/3/library/re.html\n",
        "\n",
        "https://www.kite.com/python/docs/nltk.word_tokenize\n",
        "\n",
        "https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
        "\n",
        "https://pythonprogramming.net/stemming-nltk-tutorial/\n",
        "\n",
        "https://www.quora.com/How-do-I-remove-punctuation-from-a-Python-string"
      ]
    }
  ]
}