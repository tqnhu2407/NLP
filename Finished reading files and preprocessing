{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "18127266.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tqnhu2407/NLP/blob/master/Finished%20reading%20files%20and%20preprocessing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTiQmIT9ZwsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DON'T CHANGE this part: import libraries\n",
        "import numpy as np\n",
        "import scipy\n",
        "import json\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import itertools"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEJnDPwBZwsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DON'T CHANGE this part: read data path\n",
        "train_set_path, valid_set_path, random_number = input().split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj5L38gpZwsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO:\n",
        "# 1. preprocess: converting text to lowercase, coverting number, tokenization, removing stopword, stemming\n",
        "# 2. embedding: hitogram matrix\n",
        "# 3. classifier using linear regression\n",
        "# 4. accuracy (for metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16BPf3TOZwsb",
        "colab_type": "text"
      },
      "source": [
        "#### Ví dụ cho phần báo cáo, nên báo cáo cho từng phần code để rõ ràng\n",
        "\n",
        "Báo cáo phần tiền xử lý: dùng xyz để tách từ, ...\n",
        "\n",
        "... Đối với những từ out-of-vocab (xuất hiện trong tập train nhưng không có ở tập valid), xử lý bằng cách ... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hoa36NkzCjp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7fqdczimRNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"train.json\", \"r\") as fin:\n",
        "    data = json.load(fin)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0hgDKCsoF5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_json(data):\n",
        "\n",
        "    overall = []\n",
        "    reviewText = []\n",
        "    # Filter out all the overall and reviewText\n",
        "    for d in data:\n",
        "        for (key, value) in d.items():\n",
        "            if key == 'overall':\n",
        "                overall.append(value)\n",
        "            if key == 'reviewText':\n",
        "                reviewText.append(value)\n",
        "    \n",
        "    return overall, reviewText"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtXnwbGsD-hK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "1e69699f-3e96-4bba-e4a0-c0ea656be044"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEv4v5D6Z4kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overall, reviewText = process_json(data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0M0Dwk8Zwsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(reviewText):\n",
        "\n",
        "    reviews = reviewText.copy()\n",
        "    stop_words = set(stopwords.words('english')) \n",
        "    new_reviews = []\n",
        "    \n",
        "    for i in range(len(reviews)):\n",
        "\n",
        "        # Lowercase all the letters\n",
        "        reviews[i] = reviews[i].lower()\n",
        "        # Replace all numbers with 'num\n",
        "        reviews[i] = re.sub('\\d+', 'num', reviews[i])\n",
        "        # Remove punctuation . , ?\n",
        "        reviews[i] = re.sub(r'[^\\w\\s]', '', reviews[i])\n",
        "        # Split words\n",
        "        word_tokens = word_tokenize(reviews[i])\n",
        "        # Remove stop words\n",
        "        removed_stopwords = [w for w in word_tokens if w not in stop_words]\n",
        "        # Stemming\n",
        "        ps = PorterStemmer()\n",
        "        stemmed_sentence = [ps.stem(w) for w in removed_stopwords]\n",
        "        new_reviews.append(stemmed_sentence)\n",
        "    \n",
        "    return new_reviews"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip-s_QVTvS0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vocabs(reviews):\n",
        "\n",
        "    vocabs = []\n",
        "\n",
        "    for review in reviews:\n",
        "        for r in review:\n",
        "            if r not in vocabs:\n",
        "                vocabs.append(r)\n",
        "    \n",
        "    return vocabs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stBUyB24t3Mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedded(reviews, vocabs):\n",
        "\n",
        "    embedded = []\n",
        "\n",
        "    for r in reviews:\n",
        "        embedded.append([])\n",
        "        embedded[-1] = [r.count(v) for v in vocabs]\n",
        "    \n",
        "    return embedded"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-0T32-VqINv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_reviews = preprocess(reviewText)\n",
        "vocabs = create_vocabs(new_reviews)\n",
        "embedded = create_embedded(new_reviews, vocabs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_FeoC6dGK17",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "\n",
        "https://docs.python.org/3/library/re.html\n",
        "\n",
        "https://www.kite.com/python/docs/nltk.word_tokenize\n",
        "\n",
        "https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
        "\n",
        "https://pythonprogramming.net/stemming-nltk-tutorial/\n",
        "\n",
        "https://www.quora.com/How-do-I-remove-punctuation-from-a-Python-string"
      ]
    }
  ]
}